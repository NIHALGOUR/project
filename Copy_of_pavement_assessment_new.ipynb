{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of pavement_assessment_new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NIHALGOUR/project/blob/master/Copy_of_pavement_assessment_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo6O8XPG_cnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slkzzDc9_KaD",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pbNGSsu_2tR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6dc31ae-d74a-43e4-e6d2-f7ba0506f47e"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUEYwCm5BbT1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3fd7ba7d-9973-481b-df62-491b53990f25"
      },
      "source": [
        "!kaggle datasets download -d atulyakumar98/pothole-detection-dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading pothole-detection-dataset.zip to /content\n",
            " 95% 185M/194M [00:02<00:00, 63.4MB/s]\n",
            "100% 194M/194M [00:03<00:00, 67.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPIKh4tcIhZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the important libraries\n",
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import random\n",
        "from shutil import copyfile\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZKDTOLgK9KH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unzipping the data to local tmp directory\n",
        "local_zip = '/content/pothole-detection-dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/unzipped_data')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW0ulVpMLmsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the directories for the traning and testing \n",
        "\n",
        "try:\n",
        "    os.mkdir('/tmp/pothole-v-normal')\n",
        "    os.mkdir('/tmp/pothole-v-normal/training')\n",
        "    os.mkdir('/tmp/pothole-v-normal/testing')\n",
        "    os.mkdir('/tmp/pothole-v-normal/training/normal')\n",
        "    os.mkdir('/tmp/pothole-v-normal/training/pothole')\n",
        "    os.mkdir('/tmp/pothole-v-normal/testing/normal')\n",
        "    os.mkdir('/tmp/pothole-v-normal/testing/pothole')\n",
        "except OSError:\n",
        "    print(\"Exception\")\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4auMK2ILmpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Spliting the data into training and testing\n",
        "\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "    files = []\n",
        "    for filename in os.listdir(SOURCE):\n",
        "        file = SOURCE + filename\n",
        "        if os.path.getsize(file) > 0:\n",
        "            files.append(filename)\n",
        "        else:\n",
        "            print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "    training_length = int(len(files) * SPLIT_SIZE)\n",
        "    testing_length = int(len(files) - training_length)\n",
        "    shuffled_set = random.sample(files, len(files))\n",
        "    training_set = shuffled_set[0:training_length]\n",
        "    testing_set = shuffled_set[-testing_length:]\n",
        "\n",
        "    for filename in training_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TRAINING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "    for filename in testing_set:\n",
        "        this_file = SOURCE + filename\n",
        "        destination = TESTING + filename\n",
        "        copyfile(this_file, destination)\n",
        "\n",
        "\n",
        "NORMAL_SOURCE_DIR = \"/tmp/unzipped_data/normal/\"\n",
        "TRAINING_NORMAL_DIR = \"/tmp/pothole-v-normal/training/normal/\"\n",
        "TESTING_NORMAL_DIR = \"/tmp/pothole-v-normal/testing/normal/\"\n",
        "POTHOLE_SOURCE_DIR = \"/tmp/unzipped_data/potholes/\"\n",
        "TRAINING_POTHOLE_DIR = \"/tmp/pothole-v-normal/training/pothole/\"\n",
        "TESTING_POTHOLE_DIR = \"/tmp/pothole-v-normal/testing/pothole/\"\n",
        "\n",
        "split_size = .95\n",
        "split_data(NORMAL_SOURCE_DIR, TRAINING_NORMAL_DIR, TESTING_NORMAL_DIR, split_size)\n",
        "split_data(POTHOLE_SOURCE_DIR, TRAINING_POTHOLE_DIR, TESTING_POTHOLE_DIR, split_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVUSSGkVUeU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "#Downloding the weights of the inception V3\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (250, 250, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "pre_trained_model.summary()\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHIGIWnAUg5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "x = layers.Conv2D(64,(3,3),activation='relu')(last_output)\n",
        "\n",
        "x = layers.Dropout(0.2)(x)  \n",
        "\n",
        "x = layers.MaxPool2D(2,2)(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "\n",
        "x = layers.Dense(1, activation='sigmoid')(x)           \n",
        "\n",
        "model2= Model(pre_trained_model.input, x) \n",
        "\n",
        "model2.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model2.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJPyDEzOqrKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = '/tmp/pothole-v-normal'\n",
        "train_dir = os.path.join(base_dir, 'training')\n",
        "validation_dir = os.path.join(base_dir, 'testing')\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=0.2,horizontal_flip=True,vertical_flip=True,fill_mode='nearest')\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, \n",
        "        target_size=(250, 250),  \n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(250, 250),\n",
        "        batch_size=10,\n",
        "        class_mode='binary')\n",
        "\n",
        "history = model2.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=5, \n",
        "      epochs=50,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=15,\n",
        "      verbose=2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyfsrICOGbyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.save('/tmp/testing_model_first.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4182H81Sx1h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fb1a401-a4ad-417c-933f-fdf1bfa7e9e4"
      },
      "source": [
        "label_map = (train_generator.class_indices)\n",
        "print(label_map)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'normal': 0, 'pothole': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZWPcmKWO303",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW4OnhKuM7mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "print(uploaded)\n",
        "for fn in uploaded.keys():\n",
        "  \n",
        "  # print(fn)\n",
        "  # # predicting images\n",
        "  # path = fn\n",
        "  # img = image.load_img(path, target_size=(250, 250))\n",
        "  # x = image.img_to_array(img)\n",
        "  # x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  # images = np.vstack([x])\n",
        "  # classes = model2.predict(images, batch_size=6)\n",
        "  # print(fn)\n",
        "  # # if(classes[0][0]>=0.5):\n",
        "  # #   classes[0][0]=1\n",
        "  # # else:\n",
        "  # #   classes[0][0]=0\n",
        "  # print(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJFbZqJgPteU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}